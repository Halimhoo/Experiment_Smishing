{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d448a2",
   "metadata": {},
   "source": [
    "# Project Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f03c82",
   "metadata": {},
   "source": [
    "Establishing Dataset\n",
    "Dataset Taken from \n",
    "\n",
    "https://data.mendeley.com/datasets/f45bkkt8pr/1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c53366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements\n",
    "#!pip install pandas \n",
    "#!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c584dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "504ce42f",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a21575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "import pandas as pd\n",
    "\n",
    "#dataset = dataset.reset_index(drop=True, inplace=True)\n",
    "#Local file path - CHANGE TO YOUR LOCAL FILES\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\Current Task\\SIT746\\Project\\spam.csv\"\n",
    "#file_path = r\"C:\\Users\\user\\Desktop\\Current Task\\SIT746\\Project\\Dataset_5971\\Dataset_5971.csv\"\n",
    "\n",
    "#reading\n",
    "dataset = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da3eb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will �_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will �_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a9a7d",
   "metadata": {},
   "source": [
    "## Preposessing Phase\n",
    "\n",
    "    OPERATION - STATUS\n",
    "    Lowercase - Done\n",
    "    Spelling  - GOT PROBLEM - many words cannot be corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea98c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operation Lower Case\n",
    "\n",
    "#testing phase\n",
    "def lowercase_testing():\n",
    "    test_text = \"This IS a STRESS TEST to for LOWERCASING words\"\n",
    "    test_text = test_text.lower()\n",
    "    print(test_text)\n",
    "\n",
    "#test below to see if its working.\n",
    "#lowercase_testing()\n",
    "\n",
    "#################################################\n",
    "\n",
    "#the operation begin\n",
    "#column = 'TEXT' #we just want to lower the column dataset\n",
    "\n",
    "def lowercase_testing(column):\n",
    "    dataset[column] = dataset[column].str.lower()\n",
    "\n",
    "### Lowercase Operation is DONE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f7c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operation Spelling Correction\n",
    "\n",
    "#importing libraries\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "#testing phase\n",
    "def spelling_correction_testing():\n",
    "    \n",
    "    test = \"my name is kusruthi \" #experiment the words \n",
    "    \n",
    "    split_words = test.split() #splitting the words \n",
    "    correction_words = [] #make place to store the words\n",
    "    \n",
    "    #sometimes there is word that no need for correction.\n",
    "    for word in split_words:\n",
    "        correction = SpellChecker().correction(word)\n",
    "        if correction is None:\n",
    "            correction_words.append(word)\n",
    "        else:\n",
    "            correction_words.append(correction)\n",
    "            \n",
    "    #collect the words\n",
    "    final_text = ' '.join(correction_words)\n",
    "    print(final_text)\n",
    "\n",
    "\n",
    "#NOTE\n",
    "#from the test, there are some text is not properly corrected, but some do. good enough lmao\n",
    "#I dont know if I need to maintain this preprocessing or not but yeah.\n",
    "\n",
    "#################################################\n",
    "\n",
    "#operation begin\n",
    "#since the there are many iteration, need to make a function for each line so here we go.\n",
    "def spelling_correction(text):\n",
    "    split_words = text.split() #splitting the text into words\n",
    "    correction_words = [] #make place to store the words\n",
    "    \n",
    "    for word in split_words:\n",
    "        correction = SpellChecker().correction(word)\n",
    "        if correction is None:\n",
    "            correction_words.append(word)\n",
    "        else:\n",
    "            correction_words.append(correction)\n",
    "\n",
    "    correction_final = ' '.join(correction_words)\n",
    "    return correction_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73366fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONGRATULATION Preprocessing Success\n"
     ]
    }
   ],
   "source": [
    "#Here are the part where we initiate the prepocessing part. To make easier to pick which one we want to use.\n",
    "\n",
    "#column_name\n",
    "text_column = 'v2' #for old dataset v2 for new dataset TEXT\n",
    "label_column = 'v1' #for old dataset v1 for new dataset LABEL\n",
    "\n",
    "#lowercase Operation\n",
    "lowercase_testing(column_name) #- We want to lowercase the columnt text only\n",
    "\n",
    "\n",
    "#Spelling Correction Operation - ERROR\n",
    "#dataset['TEXT'] = dataset['TEXT'].apply(spelling_correction)\n",
    "\n",
    "\n",
    "#Preprocessing is done\n",
    "print('CONGRATULATION Preprocessing Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1e919",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf0a5d38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Bag of Words\n",
    "\n",
    "#importing\n",
    "from sklearn.feature_extraction.text import CountVectorizer #IDK why theres warning jesus\n",
    "\n",
    "def BOW_Extraction(): #have better results\n",
    "    #create countvectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    #Operation begin\n",
    "    # Fit and transform the 'text' column into BoW representation\n",
    "    Extraction = vectorizer.fit_transform(dataset[column_name])\n",
    "    return Extraction \n",
    "\n",
    "#TF-IDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def TFID():\n",
    "    #create vectorizer\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    \n",
    "    #create the data\n",
    "    Extraction = vectorizer.fit_transform(dataset[column_name])\n",
    "    return Extraction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8dc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "526b0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGING extraction method here\n",
    "Extraction = TFID()\n",
    "#Extraction = BOW_Extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35988501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cb4d71c",
   "metadata": {},
   "source": [
    "## Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "220f421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting Begin 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(Extraction, dataset['v1'], test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314aa4b",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01b1c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Training multiple classifier\n",
    "\n",
    "classifiers = {MultinomialNB(),\n",
    "              SVC(),\n",
    "              DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de225745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a267ebfd",
   "metadata": {},
   "source": [
    "## Model Train and Evaluates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "676b6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE EVALUATION OF MultinomialNB()\n",
      "Accuracy:\t 0.9748878923766816\n",
      "Precision:\t 0.9748878923766816\n",
      "Recall:\t\t 0.9748878923766816\n",
      "F1-score:\t 0.9748878923766816\n",
      "---------------------\n",
      "\n",
      "THE EVALUATION OF SVC()\n",
      "Accuracy:\t 0.9802690582959641\n",
      "Precision:\t 0.9802690582959641\n",
      "Recall:\t\t 0.9802690582959641\n",
      "F1-score:\t 0.9802690582959641\n",
      "---------------------\n",
      "\n",
      "THE EVALUATION OF DecisionTreeClassifier()\n",
      "Accuracy:\t 0.967713004484305\n",
      "Precision:\t 0.967713004484305\n",
      "Recall:\t\t 0.967713004484305\n",
      "F1-score:\t 0.967713004484305\n",
      "---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#train and testing\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    #evaluates\n",
    "    #Calculating the results\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "    #Printing the results\n",
    "    print(\"THE EVALUATION OF \" + str(classifier))\n",
    "    print(\"Accuracy:\\t\", accuracy)\n",
    "    print(\"Precision:\\t\", precision)\n",
    "    print(\"Recall:\\t\\t\", recall)\n",
    "    print(\"F1-score:\\t\", f1)\n",
    "    print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c570b1e2",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182468cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9dd5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ea4bcf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb80c7c",
   "metadata": {},
   "source": [
    "### Reference\n",
    "mishra, sandhya; Soni, Devpriya (2022), “SMS PHISHING DATASET FOR MACHINE LEARNING AND PATTERN RECOGNITION”, Mendeley Data, V1, doi: 10.17632/f45bkkt8pr.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
